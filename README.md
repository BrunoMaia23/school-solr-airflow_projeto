ğŸ“Š Pipeline Airflow + Solr + Docker
Este projeto implementa um pipeline de dados que formata um CSV de alunos e insere os dados no Apache Solr, com orquestraÃ§Ã£o via Apache Airflow. Tudo Ã© executado em containers Docker.

ğŸš€ Tecnologias utilizadas
Python (pandas, pysolr)

Apache Airflow

Apache Solr

Docker e Docker Compose

PostgreSQL e Redis para backend do Airflow

ğŸ“ Estrutura do projeto
school-solr-airflow/
â”œâ”€â”€ airflow/
â”‚ â”œâ”€â”€ dags/ â†’ arquivo da DAG solr_pipeline_dag.py
â”‚ â”œâ”€â”€ logs/
â”‚ â”œâ”€â”€ plugins/
â”œâ”€â”€ data/ â†’ alunos.csv e alunos_clean.csv
â”œâ”€â”€ docker/ â†’ docker-compose-airflow.yml, docker-compose-solr.yml e requirements.txt 
â”œâ”€â”€ scripts/ â†’ scripts Python de formataÃ§Ã£o e carregamento
â””â”€â”€ README.md

ğŸ“¦ PrÃ©-requisitos
Docker instalado

docker-compose instalado

ğŸ› ï¸ Como executar o pipeline
Clone o repositÃ³rio:

git clone https://github.com/seu-usuario/school-solr-airflow.git
cd school-solr-airflow

Coloque o arquivo alunos.csv na pasta data/

Inicie os containers:

docker-compose up --build -d

Acesse:

Airflow: http://localhost:8080 (usuÃ¡rio: admin / senha: admin)

Solr: http://localhost:8983/solr

No Airflow:

Ative a DAG solr_pipeline

Clique em Trigger DAG

Verifique os dados no Solr acessando a collection alunos_collection e rodando a query:

q=:&indent=true

VocÃª verÃ¡ os documentos inseridos.

ğŸ§ª Scripts
format_csv.py â†’ faz limpeza e normalizaÃ§Ã£o dos dados, usando pandas

load_to_solr.py â†’ carrega os dados para o Solr, usando pysolr

ğŸ“ ObservaÃ§Ãµes
As tarefas sÃ£o orquestradas com Airflow usando CeleryExecutor

O pipeline trata erros simples (valores nulos, campos mal formatados)

Requisitos estÃ£o em requirements.txt

âœ… Autor
Este projeto foi desenvolvido para fins de avaliaÃ§Ã£o tÃ©cnica.

ğŸ‘¤ Bruno Maia
ğŸ“§ brunomaia2304@gmail.com