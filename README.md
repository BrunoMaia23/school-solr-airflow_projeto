# Pipeline Airflow + Solr + Docker

Este projeto implementa um **pipeline de dados** que formata um CSV de alunos e insere os registros no **Apache Solr**, orquestrado pelo **Apache Airflow**. Toda a infraestrutura roda em containers Docker para facilitar o deploy e garantir portabilidade.

---

## ğŸš€ Tecnologias Utilizadas

- **Python**: pandas, pysolr
- **Apache Airflow** (CeleryExecutor)
- **Apache Solr**
- **Docker & Docker Compose**
- **PostgreSQL** (metastore do Airflow)
- **Redis** (broker Celery)

---

## ğŸ“ Estrutura do Projeto

```
school-solr-airflow/
â”œâ”€â”€ airflow/
â”‚   â”œâ”€â”€ dags/                # DefiniÃ§Ã£o da DAG (solr_pipeline_dag.py)
â”‚   â”œâ”€â”€ logs/                # Logs gerados pelo Airflow
â”‚   â””â”€â”€ plugins/             # Plugins do Airflow (vazio por padrÃ£o)
â”œâ”€â”€ data/                    # Dados de entrada e saÃ­da
â”‚   â”œâ”€â”€ alunos.csv           # CSV original com dados dos alunos
â”‚   â””â”€â”€ alunos_clean.csv     # CSV gerado pela task de formataÃ§Ã£o
â”œâ”€â”€ docker/                  # Arquivos Docker Compose e requirements
â”‚   â”œâ”€â”€ docker-compose-airflow.yml
â”‚   â”œâ”€â”€ docker-compose-solr.yml
â”‚   â””â”€â”€ requirements.txt     # pandas, pysolr
â”œâ”€â”€ scripts/                 # Scripts Python das tasks
â”‚   â”œâ”€â”€ format_csv.py        # FormataÃ§Ã£o e limpeza do CSV
â”‚   â””â”€â”€ load_to_solr.py      # InserÃ§Ã£o dos dados no Solr
â””â”€â”€ README.md                # Este arquivo
```

---

## ğŸ“¦ PrÃ©-requisitos

Antes de iniciar, instale:

- [Docker Desktop](https://www.docker.com/products/docker-desktop)
- [Docker Compose](https://docs.docker.com/compose/install/)

---

## ğŸ› ï¸ Como Executar

1. **Clone o repositÃ³rio**
   ```bash
   git clone https://github.com/BrunoMaia23/school-solr-airflow_projeto.git
   cd school-solr-airflow_projeto
   ```

2. **Copie o CSV de alunos**
   - Coloque o arquivo `alunos.csv` na pasta `data/`

3. **Suba os containers**
   ```bash
   cd docker
   docker-compose -f docker-compose-solr.yml up -d   # Solr
   docker-compose -f docker-compose-airflow.yml up --build -d  # Airflow + Celery
   ```

4. **Acesse as interfaces**
   - **Airflow UI**: http://localhost:8080  
     UsuÃ¡rio: `admin` / Senha: `admin`
   - **Solr Admin**: http://localhost:8983/solr

5. **Execute o pipeline**
   - Na Airflow UI, ative a DAG `solr_pipeline` (toggle On)
   - Clique em **Trigger DAG**

6. **Verifique no Solr**
   - No Solr Admin, selecione a **collection** `alunos_collection`  
   - Clique em **Query** e execute sem filtros (`q=*:*`)  
   - VocÃª verÃ¡ os documentos inseridos pelo pipeline

---

## ğŸ§ª DescriÃ§Ã£o dos Scripts

- **scripts/format_csv.py**  
  - LÃª `alunos.csv` com pandas
  - Remove linhas com campos obrigatÃ³rios vazios
  - Padroniza nomes e converte datas
  - Calcula idade a partir de `Data de Nascimento`
  - Salva o CSV limpo em `alunos_clean.csv`

- **scripts/load_to_solr.py**  
  - LÃª `alunos_clean.csv`
  - ConstrÃ³i documentos no formato esperado pelo Solr
  - Conecta ao Solr via pysolr e insere os documentos

---

## ğŸ“ ObservaÃ§Ãµes

- **Executor**: utiliza CeleryExecutor para escalabilidade das tasks
- **Tratamento de erros**: validaÃ§Ãµes no Python para dados faltantes e logging de falhas
- **DependÃªncias**: listadas em `docker/requirements.txt`

---

## âœ… Autor

**Bruno Maia**  
ğŸ“§ brunomaia2304@gmail.com

Este projeto foi desenvolvido para atender ao desafio tÃ©cnico de **ImportaÃ§Ã£o de Dados para o Solr com OrquestraÃ§Ã£o via Airflow**.
